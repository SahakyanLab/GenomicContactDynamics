{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dc2af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fb4cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whorunsit = 'LiezelMac' # 'LiezelMac' | 'LiezelCluster'\n",
    "\n",
    "if whorunsit == 'LiezelMac':\n",
    "    home_dir = '/Users/ltamon'\n",
    "elif whorunsit == 'LiezelCluster':\n",
    "    home_dir = '/project/sahakyanlab/ltamon'\n",
    "else:\n",
    "  print(\"The supplied <whorunsit> option is not created in the script.\")\n",
    "\n",
    "wk_dir = home_dir + '/SahakyanLab/GenomicContactDynamics/26_PredictingCp'\n",
    "csv_dir = wk_dir + '/z_ignore_git/out_makeTable'\n",
    "out_dir = wk_dir + '/out_autogluon_run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94bc5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcb = 'min2Mb'\n",
    "chrs = ['chr21']\n",
    "\n",
    "label_col = 'LABEL'\n",
    "subsample_size = ''  # subsample subset of data for quick run, input '' or any char to skip subsampling\n",
    "\n",
    "feat_regex = 'grp.compl.|grp.kmer3.|grp.kmer1.|grp.GC.'\n",
    "model_id = re.compile('[^a-zA-Z]').sub('', feat_regex)\n",
    "model_id = model_id + '_' + str(subsample_size)\n",
    "\n",
    "model_path = out_dir + '/' + 'agModel_'  + model_id \n",
    "metric = 'accuracy'\n",
    "problem_type = 'multiclass' # (options: ‘binary’, ‘multiclass’, ‘regression’, ‘quantile’)\n",
    "\n",
    "# fit()\n",
    "presets = 'good_quality'\n",
    "time_limit = 2*60 # seconds\n",
    "#holdout_frac\n",
    "\n",
    "# Baggin/stack ensembling - if enabled, dont provide tuning_data\n",
    "#num_bag_folds=5 # how many times the k-fold bagging process is repeated to further reduce variance (increasing this may further boost accuracy but will substantially increase training times, inference latency, and memory/disk usage)\n",
    "#num_bag_sets=1, \n",
    "#num_stack_levels=1 \n",
    "#auto_stack=True # Autogluon will select bagging/stacking numbers\n",
    "# specifying presets='best_quality' in fit() simply sets auto_stack=True\n",
    "\n",
    "#num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "#search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "#hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "#    'num_trials': num_trials,\n",
    "#    'scheduler' : 'local',\n",
    "#    'searcher': search_strategy,\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e1aa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_chrcsv(csv_dir, gcb, chrs):\n",
    "    \n",
    "    df = []\n",
    "    [df.append(pd.read_csv( csv_dir + '/' + gcb + '_' + chr + '_MLtbl.csv' )) for chr in chrs]\n",
    "    df = pd.concat(df)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def choose_features(df, feat_regex, label_col):\n",
    "    \n",
    "    final_regex = feat_regex + '|' + label_col\n",
    "    is_chosen = [ bool(re.search(pattern=final_regex, string=feat)) for feat in df.columns ] \n",
    "    is_todrop = [not bool for bool in is_chosen]\n",
    "    df.drop(columns=list(df.columns[is_todrop]), inplace=True)\n",
    "\n",
    "    return(df)\n",
    "    \n",
    "def switch_contact(df):\n",
    "    \n",
    "    features = np.array(df.columns)\n",
    "    is_icol = ['.i_' in feat for feat in features]\n",
    "    is_jcol = ['.j_' in feat for feat in features]\n",
    "    \n",
    "    features_switch = np.array(features)\n",
    "    features_switch[is_icol] = features[is_jcol]\n",
    "    features_switch[is_jcol] = features[is_icol]\n",
    "    \n",
    "    df_switch = df.set_axis(features_switch, axis=1, inplace=False)\n",
    "    df_switch = df_switch[features]\n",
    "    df = pd.concat([df, df_switch])\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9716f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = concat_chrcsv(csv_dir, gcb, chrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0f3ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subsampling of training data.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "except TypeError:\n",
    "        print(\"No subsampling of training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3175e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = choose_features(train_data, feat_regex, label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "628d4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = switch_contact(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c43d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/Users/ltamon/SahakyanLab/GenomicContactDynamics/26_PredictingCp/out_autogluon_run/agModel_grpcomplgrpkmer_50\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"/Users/ltamon/SahakyanLab/GenomicContactDynamics/26_PredictingCp/out_autogluon_run/agModel_grpcomplgrpkmer_50/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    50\n",
      "Train Data Columns: 72\n",
      "Label Column: LABEL\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 1 to avoid cutting too many classes.\n",
      "Train Data Class Count: 16\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7360.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  4 | ['grp.compl.ij_anvdist', 'grp.compl.ij_CIIkmer', 'grp.compl.ij_CIIG', 'grp.compl.ij_CIIalign']\n",
      "\t\t('int', [])   : 68 | ['grp.kmer3.i_AAA', 'grp.kmer3.i_AAC', 'grp.kmer3.i_AAG', 'grp.kmer3.i_AAT', 'grp.kmer3.i_ACA', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  4 | ['grp.compl.ij_anvdist', 'grp.compl.ij_CIIkmer', 'grp.compl.ij_CIIG', 'grp.compl.ij_CIIalign']\n",
      "\t\t('int', [])   : 68 | ['grp.kmer3.i_AAA', 'grp.kmer3.i_AAC', 'grp.kmer3.i_AAG', 'grp.kmer3.i_AAT', 'grp.kmer3.i_ACA', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t72 features in original data used to generate 72 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 119.89s of the 119.89s of remaining time.\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tTarget -1 is out of bounds.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1126, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1083, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 587, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 232, in _fit\n",
      "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 503, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 217, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 222, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 252, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 587, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 287, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params['lr'], cbs=callbacks)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/callback/schedule.py\", line 119, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 256, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 193, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 245, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 193, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 240, in _do_epoch\n",
      "    self._do_epoch_validate()\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 236, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 193, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 199, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 227, in one_batch\n",
      "    self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 193, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/learner.py\", line 208, in _do_one_batch\n",
      "    self.loss_grad = self.loss_func(self.pred, *self.yb)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/losses.py\", line 54, in __call__\n",
      "    return self.func.__call__(inp, targ.view(-1) if self.flatten else targ, **kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/torch/nn/modules/loss.py\", line 1164, in forward\n",
      "    return F.cross_entropy(input, target, weight=self.weight,\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/torch/nn/functional.py\", line 3000, in cross_entropy\n",
      "    return handle_torch_function(\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/torch/overrides.py\", line 1498, in handle_torch_function\n",
      "    result = torch_func_method(public_api, types, args, kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/fastai/torch_core.py\", line 376, in __torch_function__\n",
      "    res = super().__torch_function__(func, types, args, ifnone(kwargs, {}))\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/torch/_tensor.py\", line 1121, in __torch_function__\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/Users/ltamon/opt/anaconda3/envs/automl/lib/python3.9/site-packages/torch/nn/functional.py\", line 3014, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target -1 is out of bounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 115.89s of the 115.89s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label_col, eval_metric=metric, path=model_path, problem_type=problem_type).fit(train_data, presets=presets, time_limit=time_limit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
